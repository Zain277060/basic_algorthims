{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba725b15",
   "metadata": {},
   "source": [
    "# Assignment 1 - NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af46fc",
   "metadata": {},
   "source": [
    "**Name, bhagya raj, Student no**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f31fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def181b5",
   "metadata": {},
   "source": [
    "### Provide local path and file names for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc3971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local Path here\n",
    "path=r'D:\\Assignment_1_NumPy_-1676463244/'\n",
    "\n",
    "# Classification file\n",
    "class_file_name = \"class1.csv\"\n",
    "\n",
    "# Regression file\n",
    "regr_file_name  = \"regr2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de4719",
   "metadata": {},
   "source": [
    "## Part 1 - KNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78076755",
   "metadata": {},
   "source": [
    "### 1.1 KNN classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c61ec",
   "metadata": {},
   "source": [
    "In this section you should write a function ``knn_classify(test, train, k)`` that takes train and test data as numpy ndarrays, and a k-value as an integer, and returns the class-values of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757f364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(test, train, k):\n",
    "    \n",
    "    dis=[]\n",
    "    for tr_sample in train:\n",
    "        # Calculating Euclidean distance of test data corresponding to each training point\n",
    "        dis.append(np.sqrt(np.sum( (test - tr_sample) ** 2 )))\n",
    "        \n",
    "    # Sorting for minimum distances and their indices\n",
    "    ndis=np.sort(dis)[:k]\n",
    "    nind=np.array(dis).argsort()[:k]\n",
    "    \n",
    "    # Determining labels of minimum distances neighbors\n",
    "    row_pred = train_y[nind]\n",
    "    \n",
    "    # total classes in labelled data\n",
    "    label_classes=np.unique(train_y)\n",
    "    \n",
    "    # Using inverse distancing wieghting proporation\n",
    "    inv=1/np.array(ndis)\n",
    "    # average inverse distance\n",
    "    m_inv = inv / np.sum(inv)[np.newaxis]\n",
    "    weighted_vote_count=[]\n",
    "    \n",
    "    # Loop for determining the proportional weight of each class.\n",
    "    for label in label_classes:\n",
    "        index=row_pred==label\n",
    "        weighted_vote = np.sum(m_inv[index])\n",
    "        weighted_vote_count.append(weighted_vote)\n",
    "    probable_class_index = np.argmax(weighted_vote_count)\n",
    "    label=label_classes[probable_class_index]\n",
    "    \n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8f32f",
   "metadata": {},
   "source": [
    "### 1.2 Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454d320",
   "metadata": {},
   "source": [
    "In this section you should read the data. Then split it randomly into train (60%), validation (20%), and test (20%) data. Use the train and validation data to find k-value giving the best classification result. Then use this k-value to classify the test data and report your findings: the k-value and the percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacb55fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Correct Prediction of Validation Data = 85.0 %\n",
      "Percentage Correct Prediction of Test Data = 87.5 %\n",
      "Best K Nearest Neighbor value (k) = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uploading data from local machine\n",
    "#path = r'D:\\freelance_projects\\Assignment_1_NumPy_-1676463244/class2.csv'\n",
    "data=np.genfromtxt(path+class_file_name, delimiter=',')[1:]\n",
    "\n",
    "\n",
    "#Splitting dataset into training, validating and testing as according to implied ratios.\n",
    "tr_split=int(0.6*len(data))\n",
    "val_split=int(0.8*len(data))\n",
    "\n",
    "#Training dataset\n",
    "train=data[:tr_split]\n",
    "train_x=train[:,1:]\n",
    "train_y=train[:,0].astype(int)\n",
    "\n",
    "#Validation dataset\n",
    "val=data[tr_split:val_split]\n",
    "val_x=val[:,1:]\n",
    "val_y=val[:,0].astype(int)\n",
    "\n",
    "#Testing dataset\n",
    "test=data[val_split:]\n",
    "test_x=test[:,1:]\n",
    "test_y=test[:,0].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# KNN Classification Implementation\n",
    "validation_result=[]\n",
    "\n",
    "#Looping K value\n",
    "for k in range(2,40):\n",
    "    val_predict=[]\n",
    "    \n",
    "    #Looping each feature of validation data\n",
    "    for v in val_x:\n",
    "        val_predict.append(knn_classify(v,train_x,k))\n",
    "    \n",
    "    # Calculating Percent Correct Predictions for Validation\n",
    "    val_pc=(np.count_nonzero(val_predict-val_y == 0)/np.array(val_predict).shape[0])*100\n",
    "    \n",
    "    #Appending Percent Correct Predictions value corresponding to each \"K\" value.\n",
    "    validation_result.append([val_pc,k])\n",
    "    \n",
    "    # Sorting Maximum Percent Correct Predictions along with its \"K\" value\n",
    "    validation_result.sort(key=lambda x: x[0],reverse=True)\n",
    "    \n",
    "    # Best Percent Correct Predictions and \"K\" value\n",
    "    best_validation_result = validation_result[0][0]\n",
    "    best_k = validation_result[0][1]\n",
    "\n",
    "# Predicting against test data using best \"K\" value   \n",
    "test_predict=[]   \n",
    "for t in test_x:\n",
    "    test_predict.append(knn_classify(t,train_x,best_k))\n",
    "\n",
    "# Calculating Percent Correct Predictions for Test\n",
    "test_pc=(np.count_nonzero(test_predict-test_y == 0)/np.array(test_predict).shape[0])*100\n",
    "\n",
    "\n",
    "#Results\n",
    "print(f'Percentage Correct Prediction of Validation Data = {np.round(best_validation_result,2)} %')\n",
    "print(f'Percentage Correct Prediction of Test Data = {np.round(test_pc,2)} %')\n",
    "print(f'Best K Nearest Neighbor value (k) = {np.round(best_k,1)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625323ea",
   "metadata": {},
   "source": [
    "## Part 2 - KNN and linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb888c12",
   "metadata": {},
   "source": [
    "### 2.1 KNN regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9147ed",
   "metadata": {},
   "source": [
    "In this section you should write a function ``knn_regression(train, test, k)`` that takes train and test data, and a k-value, and returns the regression (fitted) values of the responses of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403e46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_regression(test, train, k):\n",
    "    \n",
    "    dis=[]\n",
    "    # Calculating distancing corresponding to training data\n",
    "    for tr_sample in train:\n",
    "        dis.append(np.sqrt(np.sum( (test - tr_sample) ** 2 )))\n",
    "    \n",
    "    # Sorting the minimum distance and their indices.\n",
    "    ndis=np.sort(dis)[:k]\n",
    "    nind=np.array(dis).argsort()[:k]\n",
    "    \n",
    "    # When minimum distance is zero inverse distancing yeild infinity \n",
    "    # So in that case, we consider uses mean to calculate label.\n",
    "    if ndis[0]==0.0:\n",
    "        label=train_y[nind].mean()\n",
    "        return round(label,2)\n",
    "    # Otherwise, We are using inverse distancing method\n",
    "    else:\n",
    "        row_pred = train_y[nind]\n",
    "        inv=1/np.array(ndis)\n",
    "        label = round(np.matmul(inv, row_pred) / np.sum(inv),2)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72de3c",
   "metadata": {},
   "source": [
    "### 2.2 Linear regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc24ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(train,test,y):\n",
    "    # Calculating Beta\n",
    "    b = np.dot((np.linalg.inv(np.dot(train.T,train))), np.dot(train.T,y))\n",
    "    \n",
    "    # Taking product of test and Beta.\n",
    "    predict=np.dot(test, b)\n",
    "    \n",
    "    return predict.reshape(len(predict),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5feff",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db478d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---K Nearest Neighbour Regression:\n",
      "Residual Sum of Square (RSS) of Validation Data = 0.04 \n",
      "Residual Sum of Square (RSS) of Test Data = 0.05 \n",
      "Best K Nearest Neighbor value (k) = 3\n",
      "\n",
      "---Linear Regression:\n",
      "Residual Sum of Square (RSS) of Test Data = 0.1 \n"
     ]
    }
   ],
   "source": [
    "# Uploading data from local machine\n",
    "#path = r'D:\\freelance_projects\\Assignment_1_NumPy_-1676463244/regr2.csv' \n",
    "regr_data=np.genfromtxt(path+regr_file_name, delimiter=',')[1:]\n",
    "\n",
    "#Splitting dataset into training, validating and testing as according to implied ratios.\n",
    "# Splits\n",
    "tr_split=int(0.6*len(regr_data))\n",
    "val_split=int(0.8*len(regr_data))\n",
    "\n",
    "#Training dataset\n",
    "train=regr_data[:tr_split]\n",
    "train_x=train[:,1:]\n",
    "train_y=train[:,0]\n",
    "\n",
    "#Validation dataset\n",
    "val=regr_data[tr_split:val_split]\n",
    "val_x=val[:,1:]\n",
    "val_y=val[:,0]\n",
    "\n",
    "#Testing dataset\n",
    "test=regr_data[val_split:]\n",
    "test_x=test[:,1:]\n",
    "test_y=test[:,0]\n",
    "\n",
    "\n",
    "\n",
    "#KNN Regression Implementation\n",
    "validation_result=[]\n",
    "\n",
    "# looping \"K\" value \n",
    "for k in range(2,15):\n",
    "    val_predict=[]\n",
    "    \n",
    "    #Looping each feature of validation data\n",
    "    for v in val_x:\n",
    "        val_predict.append(knn_regression(v,train_x,k))\n",
    "    \n",
    "    # Calculating Residual Sum of Square (RSS) for validation\n",
    "    val_rss=np.sum(np.square(val_predict-val_y))\n",
    "    \n",
    "    # Appending RSS value corresponding to each \"K\" value.\n",
    "    validation_result.append([val_rss,k])\n",
    "    \n",
    "    # Sorting for minimum RSS value,to get best \"K\" value\n",
    "    validation_result.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Best RSS and K value\n",
    "    best_validation_result = validation_result[0][0]\n",
    "    best_k = validation_result[0][1]\n",
    "\n",
    "# Predicting against test data using best \"K\" value\n",
    "test_predict=[]   \n",
    "for t in test_x:\n",
    "    test_predict.append(knn_regression(t,train_x,best_k))\n",
    "    \n",
    "# Calculating Residual Sum of Square (RSS) for Test\n",
    "test_rss=np.sum(np.square(test_predict-test_y))\n",
    "\n",
    "\n",
    "\n",
    "# Linear Regression Implementation\n",
    "\n",
    "# Reshaping data according to implied instruction, inserting column of ones for features and reshaping labels.\n",
    "lr_train_x = np.append(np.ones((len(train_x),1)), train_x, axis=1)\n",
    "lr_train_y = np.array(train_y).reshape((len(train_y),1)) \n",
    "lr_test_x=np.append(np.ones((len(test_x),1)), test_x, axis=1)\n",
    "\n",
    "# Predicitng\n",
    "lr_prediction=linear_regression(lr_train_x, lr_test_x, lr_train_y)\n",
    "\n",
    "# Calculating Residual Sum of Square (RSS) of linear regression for Test\n",
    "lr_prediction_rss=np.sum(np.square(lr_prediction-test_y))\n",
    "\n",
    "#Results\n",
    "print('---K Nearest Neighbour Regression:')\n",
    "print(f'Residual Sum of Square (RSS) of Validation Data = {np.round(best_validation_result,2)} ')\n",
    "print(f'Residual Sum of Square (RSS) of Test Data = {np.round(test_rss,2)} ')\n",
    "print(f'Best K Nearest Neighbor value (k) = {np.round(best_k,1)}\\n')\n",
    "print('---Linear Regression:')\n",
    "print(f'Residual Sum of Square (RSS) of Test Data = {np.round(lr_prediction_rss,2)} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
